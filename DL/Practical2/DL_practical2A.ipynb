{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dfb61b0",
   "metadata": {},
   "source": [
    "## 1. Multiclass classification using Deep Neural Networks: Example: Use the OCR letter recognition dataset https://archive.ics.uci.edu/ml/datasets/letter+recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4717e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dd1ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'letter-recognition.data'\n",
    "columns = ['letter'] + [f'feature_{i}' for i in range(16)]\n",
    "df = pd.read_csv(data_path, names=columns)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['letter'])\n",
    "X = df.drop(['letter', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9343dd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>feature_11</th>\n",
       "      <th>feature_12</th>\n",
       "      <th>feature_13</th>\n",
       "      <th>feature_14</th>\n",
       "      <th>feature_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5   \n",
       "0          2          8          3          5          1          8  \\\n",
       "1          5         12          3          7          2         10   \n",
       "2          4         11          6          8          6         10   \n",
       "3          7         11          6          6          3          5   \n",
       "4          2          1          3          1          1          8   \n",
       "\n",
       "   feature_6  feature_7  feature_8  feature_9  feature_10  feature_11   \n",
       "0         13          0          6          6          10           8  \\\n",
       "1          5          5          4         13           3           9   \n",
       "2          6          2          6         10           3           7   \n",
       "3          9          4          6          4           4          10   \n",
       "4          6          6          6          6           5           9   \n",
       "\n",
       "   feature_12  feature_13  feature_14  feature_15  \n",
       "0           0           8           0           8  \n",
       "1           2           8           4          10  \n",
       "2           3           7           3           9  \n",
       "3           6          10           2           8  \n",
       "4           1           7           5          10  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e593fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19\n",
       "1     8\n",
       "2     3\n",
       "3    13\n",
       "4     6\n",
       "Name: target, dtype: int32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "401d2c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishigandha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3337 - loss: 2.4628 - val_accuracy: 0.6955 - val_loss: 1.0685\n",
      "Epoch 2/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7227 - loss: 1.0003 - val_accuracy: 0.7828 - val_loss: 0.7870\n",
      "Epoch 3/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7768 - loss: 0.7805 - val_accuracy: 0.7713 - val_loss: 0.7926\n",
      "Epoch 4/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.6689 - val_accuracy: 0.8378 - val_loss: 0.5718\n",
      "Epoch 5/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.5692 - val_accuracy: 0.8100 - val_loss: 0.5833\n",
      "Epoch 6/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8460 - loss: 0.5148 - val_accuracy: 0.8512 - val_loss: 0.4876\n",
      "Epoch 7/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8535 - loss: 0.4795 - val_accuracy: 0.8615 - val_loss: 0.4321\n",
      "Epoch 8/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 0.4270 - val_accuracy: 0.8785 - val_loss: 0.4011\n",
      "Epoch 9/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8856 - loss: 0.3788 - val_accuracy: 0.8777 - val_loss: 0.3891\n",
      "Epoch 10/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.3639 - val_accuracy: 0.8875 - val_loss: 0.3599\n",
      "Total training time: 19.68 seconds\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.3465\n",
      "Test Accuracy: 0.887499988079071\n"
     ]
    }
   ],
   "source": [
    "# Build the deep neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(16,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))  # 26 classes for letters\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate total training time\n",
    "training_time = end_time - start_time\n",
    "print(\"Total training time: {:.2f} seconds\".format(training_time))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b16ba903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "[[9.7749192e-01 2.9982129e-06 1.2240369e-05 1.8952750e-06 3.4258192e-05\n",
      "  5.8451974e-07 3.7709991e-03 4.2734639e-04 4.5839646e-05 2.5598871e-04\n",
      "  3.7967495e-04 1.1825361e-03 4.4024017e-07 1.2451817e-07 1.4378053e-04\n",
      "  1.0677839e-05 8.1214672e-03 1.1882938e-04 2.4871808e-03 7.7200628e-11\n",
      "  6.0803096e-09 3.9698902e-09 1.2276779e-12 2.1896457e-04 5.3009064e-08\n",
      "  5.2920980e-03]]\n",
      "The predicted class is: 0\n",
      "Prediction time: 0.22 seconds\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "import numpy as np\n",
    "new_data = np.array([1,1,3,2,1,8,2,2,2,8,2,8,1,6,2,7]).reshape(1, -1)\n",
    "\n",
    "start_time = time.time()\n",
    "# Use the model to make predictions\n",
    "predictions = model.predict(new_data)\n",
    "end_time = time.time()\n",
    "print(predictions)\n",
    "\n",
    "# Display the predictions\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(f'The predicted class is: {predicted_class}')\n",
    "\n",
    "prediction_time = end_time - start_time\n",
    "print(f\"Prediction time: {prediction_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e2a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 0, which corresponds to the letter: A\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
    "    10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T',\n",
    "    20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'\n",
    "}\n",
    "# Display the predicted class using the mapping\n",
    "predicted_letter = class_mapping[predicted_class]\n",
    "print(f'The predicted class is: {predicted_class}, which corresponds to the letter: {predicted_letter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec7ce1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter values for the 17 features separated by commas: 1,1,3,2,1,8,2,2,2,8,2,8,1,6,2,7\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step\n",
      "\n",
      "The predicted class is: 0 i.e. A\n"
     ]
    }
   ],
   "source": [
    "#dummy = 7,11,6,6,3,5,9,4,6,4,4,10,6,10,2,8\n",
    "\n",
    "# Take input from the user\n",
    "user_input = input(\"Enter values for the 17 features separated by commas: \")\n",
    "user_input_list = [int(x) for x in user_input.split(',')]\n",
    "\n",
    "# Convert the user input to a NumPy array\n",
    "new_data = np.array(user_input_list).reshape(1, -1)\n",
    "\n",
    "# Use the model to make predictions\n",
    "predictions = model.predict(new_data)\n",
    "#print(predictions)\n",
    "# Display the predictions\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(f'\\nThe predicted class is: {predicted_class} i.e. {class_mapping[predicted_class]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c094378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171ec8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
