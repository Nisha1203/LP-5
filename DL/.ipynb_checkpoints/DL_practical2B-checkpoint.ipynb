{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "441e7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23b0f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ecfebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60989e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and preprocess the dataset\n",
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "\n",
    "# Map 'positive' to 1 and 'negative' to 0\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(df['review'])\n",
    "X = tokenizer.texts_to_sequences(df['review'])\n",
    "X = pad_sequences(X, padding='pre', maxlen=100)\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605ffe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define the deep neural network model architecture\n",
    "\n",
    "embedding_dim = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=embedding_dim))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551ec019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 144ms/step - accuracy: 0.7488 - loss: 0.5035 - val_accuracy: 0.8621 - val_loss: 0.3252\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 142ms/step - accuracy: 0.8619 - loss: 0.3383 - val_accuracy: 0.8550 - val_loss: 0.3383\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 122ms/step - accuracy: 0.8796 - loss: 0.2905 - val_accuracy: 0.8667 - val_loss: 0.3166\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 121ms/step - accuracy: 0.8943 - loss: 0.2612 - val_accuracy: 0.8626 - val_loss: 0.3211\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 115ms/step - accuracy: 0.9094 - loss: 0.2245 - val_accuracy: 0.8635 - val_loss: 0.3205\n",
      "Training time: 415.07 seconds\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - accuracy: 0.8620 - loss: 0.3249\n",
      "Test Loss: 0.3205375075340271\n",
      "Test Accuracy: 0.8634999990463257\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test))\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "print(f\"Training time: {training_time:.2f} seconds\")\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3362fce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Make predictions on new data (dynamic input)\n",
    "while True:\n",
    "    user_input = input(\"Enter a movie review: \")\n",
    "    # Preprocess the user input\n",
    "    input_sequence = tokenizer.texts_to_sequences([user_input])\n",
    "    input_sequence = pad_sequences(input_sequence, padding='pre', maxlen=100)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Make prediction\n",
    "    prediction = model.predict(input_sequence)[0][0]\n",
    "    \n",
    "    end_time = time.time()\n",
    "    # Print prediction\n",
    "    if prediction >= 0.5:\n",
    "        print(\"Predicted sentiment: Positive\")\n",
    "    else:\n",
    "        print(\"Predicted sentiment: Negative\")\n",
    "        \n",
    "        # Calculate training time\n",
    "    prediction_time = end_time - start_time\n",
    "    print(f\"Prediction time: {prediction_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e044f",
   "metadata": {},
   "source": [
    "Example:-\n",
    "\n",
    "Movie:- 12th fail\n",
    "Positive review:-\n",
    "\n",
    "Must watch movie for every aspirants. The movie based on real life story. The struggle faced by a main character showed \n",
    "beautiful in the movie which makes movie stand out. The story presented in a best way which makes you cry, laugh and \n",
    "enjoy at the same time. It's a struggle story of aspirants who want to achieve his success at any cost. It teaches us no \n",
    "matter from where you are, what's your condition you still have a chance to win. Don't lose hope. Everyone must watch the \n",
    "movie and get inspired to do something in your life. And achieve your goal. The Vikrant did the best job of his career \n",
    "potraiting a student with an atmost sincerity. Watch ylit you will never regret it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52325c97",
   "metadata": {},
   "source": [
    "Movie:- Fast X\n",
    "    \n",
    "Negative review:\n",
    "    \n",
    "Enter a movie review: I can write the exact same review for the last Transformers, last Indiana Jones, last Star Wars movies, \n",
    "last FF or last Marvel movies etc... What happaned people? Something has happened in movie industry in late 2010's - \n",
    "2017 or 18. We cannot see any decent plot, any consistent story-telling or any sympathetic characters anymore. Day after \n",
    "day we have to endure more & more imbecilic movies with idiotic characters... new movies come out and this pattern never \n",
    "changes.  It's really not an easy job to be a movie-lover as of 2020's! :(("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66679c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
