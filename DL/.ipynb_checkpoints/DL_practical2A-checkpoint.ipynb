{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dfb61b0",
   "metadata": {},
   "source": [
    "## 1. Multiclass classification using Deep Neural Networks: Example: Use the OCR letter recognition dataset https://archive.ics.uci.edu/ml/datasets/letter+recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4717e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd1ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'letter-recognition.data'\n",
    "columns = ['letter'] + [f'feature_{i}' for i in range(16)]\n",
    "df = pd.read_csv(data_path, names=columns)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['target'] = label_encoder.fit_transform(df['letter'])\n",
    "X = df.drop(['letter', 'target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "401d2c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishigandha\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.3616 - loss: 2.3427 - val_accuracy: 0.6860 - val_loss: 1.1378\n",
      "Epoch 2/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7167 - loss: 1.0156 - val_accuracy: 0.7575 - val_loss: 0.8308\n",
      "Epoch 3/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7723 - loss: 0.7999 - val_accuracy: 0.8095 - val_loss: 0.6777\n",
      "Epoch 4/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8035 - loss: 0.6702 - val_accuracy: 0.8075 - val_loss: 0.6442\n",
      "Epoch 5/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8223 - loss: 0.5935 - val_accuracy: 0.8422 - val_loss: 0.5428\n",
      "Epoch 6/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8434 - loss: 0.5219 - val_accuracy: 0.8460 - val_loss: 0.5167\n",
      "Epoch 7/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8558 - loss: 0.4632 - val_accuracy: 0.8645 - val_loss: 0.4622\n",
      "Epoch 8/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8687 - loss: 0.4351 - val_accuracy: 0.8733 - val_loss: 0.4053\n",
      "Epoch 9/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8779 - loss: 0.3900 - val_accuracy: 0.8842 - val_loss: 0.3888\n",
      "Epoch 10/10\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.3601 - val_accuracy: 0.8873 - val_loss: 0.3642\n",
      "Total training time: 20.11 seconds\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.3550\n",
      "Test Accuracy: 0.8872500061988831\n"
     ]
    }
   ],
   "source": [
    "# Build the deep neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(16,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(26, activation='softmax'))  # 26 classes for letters\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# End time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate total training time\n",
    "training_time = end_time - start_time\n",
    "print(\"Total training time: {:.2f} seconds\".format(training_time))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b16ba903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step\n",
      "[[3.8701646e-06 9.2692899e-05 5.1929140e-03 1.8238300e-03 8.9476633e-01\n",
      "  1.5207522e-03 3.7585862e-02 2.1858709e-02 8.5406756e-04 3.4330526e-04\n",
      "  1.4499050e-02 6.0376478e-03 2.7781562e-06 3.3125950e-06 4.0845369e-04\n",
      "  9.9264935e-07 3.1073753e-06 4.5243163e-05 1.2841637e-02 2.4825693e-04\n",
      "  3.3086024e-05 9.2459197e-07 2.4348881e-10 1.6457513e-03 1.8929333e-07\n",
      "  1.8721838e-04]]\n",
      "The predicted class is: 4\n",
      "Prediction time: 0.29 seconds\n"
     ]
    }
   ],
   "source": [
    "# Given data\n",
    "import numpy as np\n",
    "new_data = np.array([4, 7, 5, 5, 4, 6, 7, 3, 7, 11, 8, 9, 3, 8, 4, 8]).reshape(1, -1)\n",
    "\n",
    "start_time = time.time()\n",
    "# Use the model to make predictions\n",
    "predictions = model.predict(new_data)\n",
    "end_time = time.time()\n",
    "print(predictions)\n",
    "\n",
    "# Display the predictions\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(f'The predicted class is: {predicted_class}')\n",
    "\n",
    "prediction_time = end_time - start_time\n",
    "print(f\"Prediction time: {prediction_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8e2a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is: 4, which corresponds to the letter: E\n"
     ]
    }
   ],
   "source": [
    "class_mapping = {\n",
    "    0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',\n",
    "    10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T',\n",
    "    20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'\n",
    "}\n",
    "\n",
    "# Display the predicted class using the mapping\n",
    "predicted_letter = class_mapping[predicted_class]\n",
    "print(f'The predicted class is: {predicted_class}, which corresponds to the letter: {predicted_letter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec7ce1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter values for the 17 features separated by commas: 7,11,6,6,3,5,9,4,6,4,4,10,6,10,2,8\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "The predicted class is: 13 i.e. N\n"
     ]
    }
   ],
   "source": [
    "#dummy = 7,11,6,6,3,5,9,4,6,4,4,10,6,10,2,8\n",
    "\n",
    "# Take input from the user\n",
    "user_input = input(\"Enter values for the 17 features separated by commas: \")\n",
    "user_input_list = [int(x) for x in user_input.split(',')]\n",
    "\n",
    "# Convert the user input to a NumPy array\n",
    "new_data = np.array(user_input_list).reshape(1, -1)\n",
    "\n",
    "# Use the model to make predictions\n",
    "predictions = model.predict(new_data)\n",
    "#print(predictions)\n",
    "# Display the predictions\n",
    "predicted_class = np.argmax(predictions)\n",
    "print(f'\\nThe predicted class is: {predicted_class} i.e. {class_mapping[predicted_class]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c094378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
